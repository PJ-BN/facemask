{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQFBpQWEiusA",
        "outputId": "aa518f62-268c-4fc1-911f-79c1779427e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-02 07:22:07--  https://raw.githubusercontent.com/PJ-BN/deeplearning/main/imagehelper.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10449 (10K) [text/plain]\n",
            "Saving to: ‘imagehelper.py’\n",
            "\n",
            "\rimagehelper.py        0%[                    ]       0  --.-KB/s               \rimagehelper.py      100%[===================>]  10.20K  --.-KB/s    in 0s      \n",
            "\n",
            "2022-12-02 07:22:07 (90.7 MB/s) - ‘imagehelper.py’ saved [10449/10449]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/PJ-BN/deeplearning/main/imagehelper.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from imagehelper import unzip_data\n",
        "\n",
        "data = unzip_data(\"data.zip\")"
      ],
      "metadata": {
        "id": "DoUYzTr6j9ok"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imagehelper import plot_random_images\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "# from model import modeldata\n",
        "from tensorflow.keras.utils import image_dataset_from_directory\n",
        "\n",
        "# dir = '/home/zoro/Documents/machinelearningpratice/deep/face_mask/data'\n",
        "\n",
        "datas = image_dataset_from_directory(\"data\",\n",
        "                                    labels='inferred',\n",
        "                                    batch_size=32,\n",
        "                                    image_size=(224, 224),\n",
        "                                    label_mode='binary')\n",
        "\n",
        "\n",
        "# model1 = modeldata(image_data)\n",
        "# print(model1.summary())\n",
        "\n",
        "\n",
        "\n",
        "inputs = keras.Input(shape=(224, 224, 3), name=\"input_layer\")\n",
        "# x = augemented_data(inputs)\n",
        "x = layers.Conv2D(50, 10, activation=\"relu\")(inputs)\n",
        "x = layers.Conv2D(50, 10, activation=\"relu\")(x)\n",
        "x = layers.MaxPool2D(2)(x)\n",
        "x = layers.Conv2D(50, 10, activation=\"relu\")(x)\n",
        "x = layers.MaxPool2D(2)(x)\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "x = keras.layers.Dense(1, activation=\"relu\")(x)\n",
        "\n",
        "output = keras.layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")(x)\n",
        "\n",
        "model_0 = keras.Model(inputs, output)\n",
        "\n",
        "model_0.compile(optimizer='adam',\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "history_0 = model_0.fit(datas, epochs=5, steps_per_epoch=len(datas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UpSgpffbjfXj",
        "outputId": "e991d659-a71d-48ea-8637-f791df954738"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 331 files belonging to 2 classes.\n",
            "Epoch 1/5\n",
            "11/11 [==============================] - 22s 422ms/step - loss: 0.7527 - accuracy: 0.4864\n",
            "Epoch 2/5\n",
            "11/11 [==============================] - 2s 203ms/step - loss: 0.6932 - accuracy: 0.4864\n",
            "Epoch 3/5\n",
            "11/11 [==============================] - 2s 201ms/step - loss: 0.6932 - accuracy: 0.4864\n",
            "Epoch 4/5\n",
            "11/11 [==============================] - 2s 202ms/step - loss: 0.6931 - accuracy: 0.5196\n",
            "Epoch 5/5\n",
            "11/11 [==============================] - 2s 201ms/step - loss: 0.6931 - accuracy: 0.5136\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lens = [0.3, 0.3]\n",
        "\n",
        "augemented_data = keras.Sequential([\n",
        "    layers.Rescaling(1./255),\n",
        "    layers.RandomFlip(),\n",
        "    layers.RandomRotation(lens),\n",
        "    # layers.RandomWidth(lens),\n",
        "    # layers.RandomHeight(lens),\n",
        "    layers.RandomZoom(height_factor=lens, width_factor=lens)\n",
        "])"
      ],
      "metadata": {
        "id": "xiL5EPXYmKJJ"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(224, 224, 3), name=\"input_layer\")\n",
        "x = augemented_data(inputs)\n",
        "\n",
        "x = layers.Conv2D(100, 10, activation=\"relu\")(x)\n",
        "x = layers.Conv2D(100, 10, activation=\"relu\")(x)\n",
        "x = layers.MaxPool2D(2)(x)\n",
        "x = layers.Conv2D(500, 10, activation=\"relu\")(x)\n",
        "x = layers.MaxPool2D(2)(x)\n",
        "x = layers.Conv2D(500, 10, activation=\"relu\")(x)\n",
        "x = layers.MaxPool2D(2)(x)\n",
        "x = layers.Conv2D(100, 10, activation=\"relu\")(x)\n",
        "x = layers.MaxPool2D(2)(x)\n",
        "\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "x = keras.layers.Dense(1, activation=\"relu\")(x)\n",
        "\n",
        "output = keras.layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")(x)\n",
        "\n",
        "model_0 = keras.Model(inputs, output)\n",
        "\n",
        "model_0.compile(optimizer=tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.0001),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "history_0 = model_0.fit(datas, epochs=5, steps_per_epoch=len(datas))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oSXzCQMnkid8",
        "outputId": "011888d2-df8c-41f1-fee7-e38b1b6a2145"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "11/11 [==============================] - 52s 3s/step - loss: 0.7058 - accuracy: 0.5710\n",
            "Epoch 2/5\n",
            "11/11 [==============================] - 23s 2s/step - loss: 0.6695 - accuracy: 0.6163\n",
            "Epoch 3/5\n",
            "11/11 [==============================] - 23s 2s/step - loss: 0.5295 - accuracy: 0.7915\n",
            "Epoch 4/5\n",
            "11/11 [==============================] - 24s 2s/step - loss: 0.3960 - accuracy: 0.9486\n",
            "Epoch 5/5\n",
            "11/11 [==============================] - 24s 2s/step - loss: 0.3793 - accuracy: 0.9668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "full_datas = unzip_data(\"datafull.zip\")"
      ],
      "metadata": {
        "id": "i2JiHyjomksg"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = image_dataset_from_directory(\"data/train\",\n",
        "                                    labels='inferred',\n",
        "                                    batch_size=10,\n",
        "                                    image_size=(224, 224),\n",
        "                                    label_mode='binary')\n",
        "test_data = image_dataset_from_directory(\"data/train\",\n",
        "                                    labels='inferred',\n",
        "                                    batch_size=10,\n",
        "                                    image_size=(224, 224),\n",
        "                                    label_mode='binary')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw40nNsBx_qW",
        "outputId": "48218571-149b-467b-aaff-f5b152439851"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 264 files belonging to 2 classes.\n",
            "Found 264 files belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = keras.Input(shape=(224, 224, 3), name=\"input_layer\")\n",
        "x = augemented_data(inputs)\n",
        "\n",
        "x = layers.Conv2D(100, 10, activation=\"relu\")(x)\n",
        "x = layers.Conv2D(100, 10, activation=\"relu\")(x)\n",
        "x = layers.MaxPool2D(2)(x)\n",
        "x = layers.Conv2D(500, 10, activation=\"relu\")(x)\n",
        "x = layers.MaxPool2D(2)(x)\n",
        "x = layers.Conv2D(500, 10, activation=\"relu\")(x)\n",
        "x = layers.MaxPool2D(2)(x)\n",
        "x = layers.Conv2D(100, 10, activation=\"relu\")(x)\n",
        "x = layers.MaxPool2D(2)(x)\n",
        "\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "x = keras.layers.Dense(1, activation=\"relu\")(x)\n",
        "\n",
        "output = keras.layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")(x)\n",
        "\n",
        "model_0 = keras.Model(inputs, output)\n",
        "\n",
        "model_0.compile(optimizer=tf.keras.optimizers.Adam(\n",
        "    learning_rate=0.0001),\n",
        "                loss='binary_crossentropy',\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "history_0 = model_0.fit(train_data, epochs=5, steps_per_epoch=len(datas), validation_data=test_data, validation_steps=len(test_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lcxwVpAFyKS_",
        "outputId": "c0e1d003-1a72-432e-9cd5-cade3d21f0b2"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "11/11 [==============================] - 34s 2s/step - loss: 0.6932 - accuracy: 0.4364 - val_loss: 0.6931 - val_accuracy: 0.5189\n",
            "Epoch 2/5\n",
            "11/11 [==============================] - 15s 1s/step - loss: 0.6931 - accuracy: 0.5455 - val_loss: 0.6931 - val_accuracy: 0.5189\n",
            "Epoch 3/5\n",
            " 5/11 [============>.................] - ETA: 9s - loss: 0.6932 - accuracy: 0.3864"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 55 batches). You may need to use the repeat() function when building your dataset.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r11/11 [==============================] - 12s 1s/step - loss: 0.6932 - accuracy: 0.3864 - val_loss: 0.6931 - val_accuracy: 0.5189\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "g7XwWT1jydca"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}